#!/bin/bash

#==============================================================================
# DESCRIPTION
#==============================================================================
# Purpose : This Script will be used to set-up Environment Variables for Job
#==============================================================================
#                        MODIFICATIONS
#==============================================================================
# Date (YYYY-MM-DD)    Programmer Name     Change Description
# -----------------    -----------------   ------------------------------------
# 2016-06-12           Soumendra Mishra    Initial Creation
# 2016-07-19           Soumendra Mishra    Changed from File-Read to DB-Read
#==============================================================================

#==============================================================================
# Reading Table Properties
#==============================================================================

  #----------------------------------------------------------------------------
  # Table Info Schema & Data
  #----------------------------------------------------------------------------
  export TABLE_INFO_SCHEMA="ea_shared"
  export TABLE_INFO_OBJECT="wc_table_info"
  
  # Service Account
  export SERVICE_ACCOUNT="srvc_ima_platform"
  export SERVICE_ACCOUNT_IMA="srvc_ima_platform"
    
  # Hive Table Info  
  #  export HIVE_DB_NAME="${TBL_INFO_HIVE_SCHEMA}" 
    export HIVE_FIELD_DELIMITER="\034"
    export HIVE_SERVER_URL="g4t8346c.houston.hp.com"
    export BEELINE="beeline -n ${SERVICE_ACCOUNT} -u jdbc:hive2://${HIVE_SERVER_URL}:10000/${HIVE_DB_NAME}"
  # export KERBEROS_REALM="EAPOCKDC.HOUSTON.HPECORP.NET"
  # export BEELINE="beeline -n srvc_wc_hdev -u 'jdbc:hive2://${HIVE_SERVER_URL}:10000//${HIVE_DB_NAME};principal=hive/${HIVE_SERVER_URL}@${KERBEROS_REALM}'"
  
  
  # Source DB Info for EHUB
  export EHUB_WEBHDFS_URL="webhdfs://g4t6526.houston.hp.com:14000/EDWExtractHub"

  #----------------------------------------------------------------------------
  # Reading Table Info Data
  #----------------------------------------------------------------------------
  hive -e "SELECT * FROM ${TABLE_INFO_SCHEMA}.${TABLE_INFO_OBJECT} WHERE target_table='${TABLE_NAME}' AND data_load_zone='RAW';" > "${JOB_HOME}/tmp/table_info_${TABLE_NAME}.txt" 2>&1

  export TABLE_INFO_FILE="${JOB_HOME}/tmp/table_info_${TABLE_NAME}.txt"

  #----------------------------------------------------------------------------
  # Validating table_info.txt file
  #----------------------------------------------------------------------------
  if [ ! -f "${TABLE_INFO_FILE}" ]
  then
      echo "[***Error***] Table info file not exists"
      exit 1
  fi

  L_TBL_INFO="`grep -w ${TABLE_NAME} ${TABLE_INFO_FILE}`"

  if [ -z "${L_TBL_INFO}" ]
  then
      echo "[***Error***] Table properties not found"
      exit 1
  fi

  #------------------------------------------------------------------------------
  # Reading Table Properties
  #------------------------------------------------------------------------------

  export TBL_INFO_TABLE_INFO_ID="`echo ${L_TBL_INFO} | awk {'print $1'}`"
  export TBL_INFO_SOURCE_SYSTEM="`echo ${L_TBL_INFO} | awk {'print $2'}`"
  export TBL_INFO_DATA_LOAD_ZONE="`echo ${L_TBL_INFO} | awk {'print $3'}`"
  export TBL_INFO_DATA_LOAD_TYPE="`echo ${L_TBL_INFO} | awk {'print $4'}`"
  export TBL_INFO_SOURCE_SCHEMA="`echo ${L_TBL_INFO} | awk {'print $5'}`"
  export TBL_INFO_SOURCE_TABLE="`echo ${L_TBL_INFO} | awk {'print $6'}`"
  export TBL_INFO_TARGET_TABLE="`echo ${L_TBL_INFO} | awk {'print $7'}`"
  export TBL_INFO_PRIMARY_KEY="`echo ${L_TBL_INFO} | awk {'print $8'}`"
  export TBL_INFO_MIN_TS="`echo ${L_TBL_INFO} | awk {'print $9'}`"
  export TBL_INFO_MAX_TS="`echo ${L_TBL_INFO} | awk {'print $10'}`"
  export TBL_INFO_SQOOP_SPLIT_BY_FLAG="`echo ${L_TBL_INFO} | awk {'print $11'}`"
  export TBL_INFO_SQOOP_SPLIT_BY_COL="`echo ${L_TBL_INFO} | awk {'print $12'}`"
  export TBL_INFO_SQOOP_SPLIT_BY_LIMIT="`echo ${L_TBL_INFO} | awk {'print $13'}`"
  export TBL_INFO_INCR_TABLE_FLAG="`echo ${L_TBL_INFO} | awk {'print $14'}`"
  export TBL_INFO_MAP_COL_NULL="`echo ${L_TBL_INFO} | awk {'print $15'}`"
  export TBL_INFO_INCR_FIL_COL="`echo ${L_TBL_INFO} | awk {'print $16'}`"
  export TBL_INFO_SOURCE_SYS_BTCH_NR="`echo ${L_TBL_INFO} | awk {'print $17'}`"
  export TBL_INFO_HIVE_SCHEMA="`echo ${L_TBL_INFO} | awk {'print $18'}`"


  export HIVE_DB_NAME="${TBL_INFO_HIVE_SCHEMA}"
  #----------------------------------------------------------------------------
  # Check for Active Reporting/Incremental Table
  #----------------------------------------------------------------------------
  if [ "${TBL_INFO_INCR_TABLE_FLAG}" == "P" ]
  then
      export TBL_INFO_INCR_PRI_TABLE="${TBL_INFO_TARGET_TABLE}_pri"
      export TBL_INFO_INCR_SEC_TABLE="${TBL_INFO_TARGET_TABLE}_sec"
  else
      export TBL_INFO_INCR_PRI_TABLE="${TBL_INFO_TARGET_TABLE}_sec"
      export TBL_INFO_INCR_SEC_TABLE="${TBL_INFO_TARGET_TABLE}_pri"
  fi
